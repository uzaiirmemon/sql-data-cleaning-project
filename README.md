# sql-data-cleaning-project and EDA on world_layoffs
This project focuses on data cleaning using SQL. Key tasks included removing duplicates, standardizing data formats, handling null and empty values, and eliminating unnecessary rows and columns. The goal was to enhance data quality and prepare the dataset for accurate analysis.
In this project, I performed data cleaning using SQL, focusing on preparing the dataset for analysis. The key tasks included:

Duplicate Removal: Identified and removed duplicate rows.
Data Standardization: Ensured data consistency in formats and structure.
Handling Null and Empty Values: Removed or filled null and empty fields where necessary.
Data Optimization: Removed unnecessary columns and rows to streamline the dataset.
This project demonstrates key data cleaning techniques to ensure data integrity and quality for further analysis.

Performed exploratory data analysis (EDA) on global layoffs data using MySQL. Cleaned the dataset by removing duplicates, handling missing values, and standardizing columns. Key insights were drawn by aggregating data using GROUP BY on company, industry, country, and year. Applied advanced queries for rolling totals, ranking with DENSE_RANK(), and calculated layoffs trends over months and years. Visualized patterns and trends to understand layoffs by various dimensions.
